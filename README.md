# Daily Papers - DoA Estimation
Automatically fetches the latest arXiv papers on Direction of Arrival (DoA) estimation and Array Signal Processing.
Strictly filtered for Signal Processing (eess.SP, eess.AS) and Audio (cs.SD) fields.

Last update: 2025-12-23

## Array
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[An Fluid Antenna Array-Enabled DOA Estimation Method: End-Fire Effect Suppression](https://arxiv.org/abs/2512.18981v1)** | 2025-12-22 | <details><summary>Show</summary><p>Direction of Arrival (DOA) estimation serves as a critical sensing technology poised to play a vital role in future intelligent and ubiquitous communication systems. Despite the development of numerous mature super-resolution algorithms, the inherent end-fire effect problem in fixed antenna arrays remains inadequately addressed. This work proposed a novel array architecture composed of fluid antennas. By exploiting the spatial reconfigurability of their positions to equivalently modulate the array steering vector and integrating it with the classical MUSIC algorithm, this approach achieved high-precision DOA estimation. Simulation results demonstrated that the proposed method delivers outstanding estimation performance even in highly challenging end-fire regions.</p></details> |  |
| **[Moment-Matching Array Processing Technique for diffuse source estimation](https://arxiv.org/abs/2512.15283v1)** | 2025-12-17 | <details><summary>Show</summary><p>Direction of Arrival (DOA) estimation is a fundamental problem in signal processing. Diffuse sources, whose power density cannot be represented with a single angular coordinate, are usually characterized based on prior assumptions, which associate the source angular density with a specific set of functions. However, these assumptions can lead to significant estimation biases when they are incorrect. This paper introduces the Moment-Matching Estimation Technique (MoMET), a low-complexity method for estimating the mean DOA, spread, and power of a narrow diffuse source without requiring prior knowledge on the source distribution. The unknown source density is characterized by its mean DOA and its first central moments, which are estimated through covariance matching techniques which fit the empirical covariance of the measurements to that modeled from the moments. The MoMET parameterization is robust to incorrect model assumptions, and numerically efficient. The asymptotic bias and covariance of the new estimator are derived and its performance is demonstrated through simulations.</p></details> |  |
| **[Adaptive MIMO Radar Architecture for Energy-Efficient Wireless Sensing in the D-Band](https://arxiv.org/abs/2309.17110v4)** | 2025-12-12 | <details><summary>Show</summary><p>The D-band offering an untapped wide bandwidth is promising for high data rate communication and high-resolution wireless sensing. However, these potentials are hindered by the low performance and energy efficiency of the D-band circuits and systems. We present an adaptive multi-input multi-output (MIMO) radar architecture for energy-efficient wireless sensing in the D-band, leveraging a reconfigurable 2D array of radar transceiver front-ends, a scaling approach for the receiver (RX) signal-to-noise ratio (SNR) and the transmitter (TX) output power ($P_{\rm TX}$) with target distance, and dynamic selection of the direction-of-arrival (DOA) estimation algorithm. The reconfigurable radar array, providing an adaptive radar resolution, enhances the energy efficiency by reducing power consumption in the radar RF front-end and lowering the computational complexity in the radar back-end. The RX SNR and the TX output power are scaled with the distance as ${\rm SNR} \propto d^{-p}$ and $P_{\rm TX} \propto d^{4-p}$, where $0 < p < 4$, leading to more efficient resource allocation in varying target distance conditions. Additionally, DOA estimation results using MUSIC and MVDR algorithms indicate that the optimum algorithm, in terms of the accuracy and computational complexity, should be selected based on the number of radar array elements. Furthermore, we develop a hardware model for the MIMO radar RF front-end to evaluate the power consumption of the TX, RX, and local oscillator (LO) distribution network. It is shown that the power consumption of the LO distribution network, which can dominate the power consumption for a large MIMO radar, can be minimized through a distribution strategy for LO amplifiers employed for compensating passive losses. Performance of the adaptive MIMO radar is evaluated in the free-space and the through-wall indoor sensing scenarios in the D-band.</p></details> |  |
| **[Rydberg Atomic Quantum Receivers for Multi-Target DOA Estimation](https://arxiv.org/abs/2501.02820v3)** | 2025-12-11 | <details><summary>Show</summary><p>Quantum sensing technologies have experienced rapid progresses since entering the `second quantum revolution'. Among various candidates, schemes relying on Rydberg atoms exhibit compelling advantages for detecting radio frequency signals. Based on this, Rydberg atomic quantum receivers (RAQRs) have emerged as a promising solution to classical wireless communication and sensing. To harness the advantages and exploit the potential of RAQRs in wireless sensing, we investigate the realization of the direction of arrival (DOA) estimation by RAQRs. Specifically, we first conceive a Rydberg atomic quantum uniform linear array (RAQ-ULA) aided wireless receiver for multi-target DOA detection and propose the corresponding signal model of this sensing system. Our model reveals that the presence of the radio-frequency local oscillator in the RAQ-ULA creates sensor gain mismatches, which degrade the DOA estimation significantly by employing the classical Estimation of Signal Parameters via Rotational Invariant Techniques (ESPRIT). To solve this sensor gain mismatch problem, we propose the Rydberg atomic quantum ESPRIT (RAQ-ESPRIT) relying on our model. Lastly, we characterize our scheme through numerical simulations, where the results exhibit that it is capable of reducing the estimation error of its classical counterpart on the order of $> 400$-fold and $> 9000$-fold in the PSL and SQL, respectively.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 7 figures, accepted by IEEE Transactions on Vehicular Technology</p></details> |
| **[A Speculative GLRT-Backed Approach for Adversarial Resilience on Deep Learning-Based Array Processing](https://arxiv.org/abs/2512.09893v1)** | 2025-12-10 | <details><summary>Show</summary><p>Classical array processing methods such as the generalized likelihood ratio test (GLRT) provide statistically grounded solutions for signal detection and direction-of-arrival (DoA) estimation, but their high computational cost limits their use in low-latency settings. Deep learning (DL) has recently emerged as an efficient alternative, offering fast inference for array processing tasks. However, DL models lack statistical guarantees and, moreover, are highly susceptible to adversarial perturbations, raising fundamental concerns about their reliability in adversarial wireless environments. To address these challenges, we propose an adversarially resilient speculative array processing framework that consists of a low-latency DL classifier backed by a theoretically-grounded GLRT validator, where DL is used for fast speculative inference and later confirmed with the GLRT. We show that second order statistics of the received array, which the GLRT operates on, are spatially invariant to L-p bounded adversarial perturbations, providing adversarial robustness and theoretically-grounded validation of DL predictions. Empirical evaluations under multiple L-p bounds, perturbation designs, and perturbation magnitudes corroborate our theoretical findings, demonstrating the superior performance of our proposed framework in comparison to multiple state-of-the-art baselines.</p></details> | <details><summary>12 pa...</summary><p>12 pages, 3 figures, 2 tables</p></details> |
| **[Efficient Decoders for Sensing Subspace Code](https://arxiv.org/abs/2512.05028v1)** | 2025-12-04 | <details><summary>Show</summary><p>Sparse antenna array sensing of source/target via direction of arrival (DoA) estimation motivates design of the sensing framework in joint communication and sensing (JCAS) systems for sixth generation (6G) communication systems. Recently, it is established by Mahdavifar, Rajamäki, and Pal that array geometry of sparse arrays has fundamental connections with the design of subspace codes in coding theory. This was then utilized to design efficient \textit{sensing subspace codes} that estimate the DoA with good resolution. Specifically, the Bose-Chowla sensing subspace code provides near optimal code design for unique DoA estimation with tight theoretical upper bound on the error performance. However, the currently known decoder for these codes, to estimate the DoA, is a traditional \textit{Maximum-a-Posterior (MAP) decoder} with complexity that is cubic with the number of antennas. In this work, we propose novel efficient decoding algorithms for sensing subspace codes, that reduce the complexity down to quadratic while providing new knobs to tune in order to tradeoff complexity with error performance. The decoders are further evaluated for their performance via Monte Carlo simulations for a range of SNRs demonstrating promising performance that smoothly approaches the MAP performance as the complexity grows from quadratic to cubic in the number of antennas.</p></details> | <details><summary>This ...</summary><p>This paper was accepted for presentation at the 59th Annual Asilomar Conference on Signals, Systems, and Computers</p></details> |
| **[Nonlinear EM-based Signal Processing](https://arxiv.org/abs/2512.04595v1)** | 2025-12-04 | <details><summary>Show</summary><p>The use of high-frequency bands, combined with antenna arrays containing an extremely large number of elements (XL-MIMO), is pushing current technology to its limits in terms of hardware complexity, latency, and power consumption. A promising approach to achieving scalable and sustainable solutions is to shift part of the signal processing directly into the electromagnetic (EM) domain. In this paper, we investigate novel architectures that harness the interaction of reconfigurable passive linear and nonlinear (NL) scattering elements positioned in the reactive near field of signal sources. The objective is to enable multifunctional linear and NL EM signal processing to occur directly "over-the-air." Numerical results highlight the potential to significantly reduce both system complexity and the number of RF chains, while still achieving key performance metrics in applications such as direction-of-arrival and position estimation, without the need for additional analog or digital processing.</p></details> |  |
| **[Covariance-Guided DFT Beam Selection for Beamspace ESPRIT in Hybrid mmWave MIMO Receivers](https://arxiv.org/abs/2512.00898v1)** | 2025-11-30 | <details><summary>Show</summary><p>We consider direction-of-arrival estimation in hybrid analog/digital mmWave MIMO receivers that employ DFT beamspace processing with a limited number of RF chains. Building on beamspace ESPRIT, we develop a covariance-guided beam selection framework that reconstructs a virtual fully digital subarray, fits a structured signal-plus-noise covariance model, and uses the resulting denoised covariance to select, for each coarse sector, a small contiguous block of DFT beams under a beam-budget constraint. The selected beams feed a sparse beamspace Unitary ESPRIT stage, so that the overall complexity is dominated by a single low-dimensional ESPRIT call while retaining a large effective aperture. Monte Carlo simulations for a 32-element uniform linear array with three paths show that, relative to a standard sectorization-based beam selector built on the same DFT codebook and ESPRIT estimator, the proposed method attains near Cramér--Rao bound accuracy at moderate array signal-to-noise ratios, substantially reduces the gap to the bound and the failure rate, and offers favorable accuracy--runtime trade-offs under dynamic RF budgets and sector-edge stress tests.</p></details> | <details><summary>22 pa...</summary><p>22 pages, 7 figures, 1 table</p></details> |
| **[DoA Estimation with Sparse Arrays: Effects of Antenna Element Patterns and Nonidealities](https://arxiv.org/abs/2511.23028v1)** | 2025-11-28 | <details><summary>Show</summary><p>This paper studies the effects of directional antenna element complex gain patterns and nonidealities in direction of arrival (DoA) estimation. We compare sparse arrays and classical uniform linear arrays, harnessing EM simulation tools to accurately model the electromagnetic behavior of both patch and Vivaldi antenna element including mutual coupling effects. We show that with sparse array configurations, the performance impacts are significant in terms of DoA estimation accuracy and operable SNR ranges. Specifically, in the scenarios considered, both the usage of directional antenna elements and a sparse array result in over 90% reduction in average direction finding error, compared to a uniform omnidirectional array with the same number of elements (in this case eight), when estimating the directions of two sources using the MUSIC algorithm. For a fixed angular RMSE, the improvements in array sensitivity are shown to yield a 4 to 15-fold increase in one-way coverage distance (assuming free-space path loss). Among the studied options, the best performance was obtained using sparse arrays with either patch or Vivaldi elements for field of views of 100$^\circ$ or 120$^\circ$, respectively.</p></details> |  |
| **[LocaGen: Sub-Sample Time-Delay Learning for Beam Localization](https://arxiv.org/abs/2512.07872v1)** | 2025-11-27 | <details><summary>Show</summary><p>The goal of LocaGen is to improve the localization performance of audio signals in the 2-D beam localization problem. LocaGen reduces sampling quantization errors through machine learning models trained on realistic synthetic data generated by a simulation. The system increases the accuracy of both direction-of-arrival (DOA) and precise location estimation of an audio beam from an array of three microphones. We demonstrate LocaGen's efficacy on a low-powered embedded system with an increased localization accuracy with a minimal increase in real-time resource usage. LocaGen was demonstrated to reduce DOA error by approximately 67% even with a microphone array of only 10 kHz in audio processing.</p></details> | 7 pages |
| **[Semi-Passive IRS Enabled Sensing with Group Movable Sensors](https://arxiv.org/abs/2511.18892v1)** | 2025-11-24 | <details><summary>Show</summary><p>The performance of the sensing system is limited by the signal attenuation and the number of receiving components. In this letter, we investigate the sensor position selection in a semi-passive intelligent reflecting surface (IRS) enabled non-line-of-sight (NLoS) sensing system. The IRS consists of passive elements and active sensors, where the sensors can receive and process the echo signal for direction-of-arrival (DoA) estimation. Motivated by the movable antenna array and fluid antenna system, we consider the case where the sensors are integrated into a group for movement and derive the corresponding Cramer-Rao bound (CRB). Then, the optimal solution for the positions of the movable sensors (MSs) to the CRB minimization problem is derived in closed form. Moreover, we characterize the relationship between the CRB and system parameters. Theoretical analysis and numerical results are provided to demonstrate the superiority of the proposed MS scheme over the fixed-position (FP) scheme.</p></details> |  |
| **[Adaptive Beam Broadening for DoA Estimation in Dynamic and Resource-Constrained DFRC Systems](https://arxiv.org/abs/2412.16661v3)** | 2025-11-18 | <details><summary>Show</summary><p>Dual-function radar communication (DFRC) systems incorporate both radar and communication functions by sharing spectrum, hardware and radio frequency (RF) chains. In this work, we consider a conceptual DFRC scheduler model which shares RF chains between radar and communication functions. If such a scheduler is tuned for prioritizing communication performance, the RF chains and time allocated to radar are less and varying. We propose a practical, low-latency and resource-aware technique for sensing the entire field-of-view (FOV) and Direction-of-Arrival (DoA) estimation in such settings by leveraging time-sliced beam allocation along with adaptive windowing. This results in a balanced cumulative array factor over the FOV thereby ensuring better DoA estimation reliability. Extensive simulation studies show that the technique has consistent target detection and angle estimation performance in all directions and adapts to varying resource availability with time.</p></details> | <details><summary>10 pa...</summary><p>10 pages, 14 figures 1) Changed system model incorporating abstract DFRC scheduler sharing RF chains 2) Reorganized text/desc. 3) Regenerated plots as per standard parameter settings, used standard colors</p></details> |
| **[A Unified Framework for Direction and Diffuseness Estimation Using Tight-Frame Microphone Arrays](https://arxiv.org/abs/2510.22183v2)** | 2025-10-28 | <details><summary>Show</summary><p>This work presents a unified framework for estimating both sound-field direction and diffuseness using practical microphone arrays with different spatial configurations. Building on covariance-based diffuseness models, we formulate a velocity-only covariance approach that enables consistent diffuseness evaluation across heterogeneous array geometries without requiring mode whitening or spherical-harmonic decomposition. Three array types -- an A-format array, a rigid-sphere array, and a newly proposed tight-frame array -- are modeled and compared through both simulations and measurement-based experiments. The results show that the tight-frame configuration achieves near-isotropic directional sampling and reproduces diffuseness characteristics comparable to those of higher-order spherical arrays, while maintaining a compact physical structure. We further examine the accuracy of direction-of-arrival estimation based on acoustic intensity within the same framework. These findings connect theoretical diffuseness analysis with implementable array designs and support the development of robust, broadband methods for spatial-sound-field characterization.</p></details> | <details><summary>36 pa...</summary><p>36 pages including 14 files</p></details> |
| **[Model-Based Learning for DOA Estimation with One-Bit Single-Snapshot Sparse Arrays](https://arxiv.org/abs/2502.17473v2)** | 2025-10-21 | <details><summary>Show</summary><p>We address the challenging problem of estimating the directions-of-arrival (DOAs) of multiple off-grid signals using a single snapshot of one-bit quantized measurements. Conventional DOA estimation methods face difficulties in tackling this problem effectively. This paper introduces a domain-knowledge-guided learning framework to achieve high-resolution DOA estimation in such a scenario, thus drastically reducing hardware complexity without compromising performance. We first reformulate DOA estimation as a maximum a posteriori (MAP) problem, unifying on-grid and off-grid scenarios under a Laplacian-type sparsity prior to effectively enforce sparsity for both uniform and sparse linear arrays. For off-grid signals, a first-order approximation grid model is embedded into the one-bit signal model. We then reinterpret one-bit sensing as a binary classification task, employing a multivariate Bernoulli likelihood with a logistic link function to enhance stability and estimation accuracy. To resolve the non-convexity inherent in the MAP formulation, we develop augmented algorithmic frameworks based on majorization-minimization principles. Further, we design model-based inference neural networks by deep unrolling these frameworks, significantly reducing computational complexity while preserving the estimation precision. Extensive simulations demonstrate the robustness of the proposed framework across a wide range of input signal-to-noise ratio values and off-grid deviations. By integrating the unified model-based priors with data-driven learning, this work bridges the gap between theoretical guarantees and practical feasibility in one-bit single-snapshot DOA estimation, offering a scalable, hardware-efficient solution for next-generation radar and communication systems.</p></details> | <details><summary>manus...</summary><p>manuscript accepted by IEEE Journal of Selected Topics in Signal Processing for publication</p></details> |
| **[MC-LExt: Multi-Channel Target Speaker Extraction with Onset-Prompted Speaker Conditioning Mechanism](https://arxiv.org/abs/2510.15437v1)** | 2025-10-17 | <details><summary>Show</summary><p>Multi-channel target speaker extraction (MC-TSE) aims to extract a target speaker's voice from multi-speaker signals captured by multiple microphones. Existing methods often rely on auxiliary clues such as direction-of-arrival (DOA) or speaker embeddings. However, DOA-based approaches depend on explicit direction estimation and are sensitive to microphone array geometry, while methods based on speaker embeddings model speaker identity in an implicit manner and may degrade in noisy-reverberant conditions. To address these limitations, we propose multi-channel listen to extract (MC-LExt), a simple but highly-effective framework for MC-TSE. Our key idea is to prepend a short enrollment utterance of the target speaker to each channel of the multi-channel mixture, providing an onset-prompted conditioning signal that can guide TSE. This design allows the deep neural network (DNN) to learn spatial and speaker identity cues jointly in a fully end-to-end manner. Experiments on noisy-reverberant benchmarks, including WHAMR! and MC-Libri2Mix, demonstrate the effectiveness of MC-TSE.</p></details> | 5 pages, 2 figures |
| **[Spatial Signal Focusing and Noise Suppression for Direction-of-Arrival Estimation in Large-Aperture 2D Arrays under Demanding Conditions](https://arxiv.org/abs/2510.10923v1)** | 2025-10-13 | <details><summary>Show</summary><p>Direction-of-Arrival (DOA) estimation in sensor arrays faces limitations under demanding conditions, including low signal-to-noise ratio, single-snapshot scenarios, coherent sources, and unknown source counts. Conventional beamforming suffers from sidelobe interference, adaptive methods (e.g., MVDR) and subspace algorithms (e.g., MUSIC) degrade with limited snapshots or coherent signals, while sparse-recovery approaches (e.g., L1-SVD) incur high computational complexity for large arrays. In this article, we construct the concept of the optimal spatial filter to solve the DOA estimation problem under demanding conditions by utilizing the sparsity of spatial signals. By utilizing the concept of the optimal spatial filter, we have transformed the DOA estimation problem into a solution problem for the optimal spatial filter. We propose the Spatial Signal Focusing and Noise Suppression (SSFNS) algorithm, which is a novel DOA estimation framework grounded in the theoretical existence of an optimal spatial filter, to solve for the optimal spatial filter and obtain DOA. Through experiments, it was found that the proposed algorithm is suitable for large aperture two-dimensional arrays and experiments have shown that our proposed algorithm performs better than other algorithms in scenarios with few snapshots or even a single snapshot, low signal-to-noise ratio, coherent signals, and unknown signal numbers in two-dimensional large aperture arrays.</p></details> |  |
| **[Perceptual Compensation of Ambisonics Recordings for Reproduction in Room](https://arxiv.org/abs/2510.10883v1)** | 2025-10-13 | <details><summary>Show</summary><p>Ambisonics is a method for capturing and rendering a sound field accurately, assuming that the acoustics of the playback room does not significantly influence the sound field. However, in practice, the acoustics of the playback room may lead to a noticeable degradation in sound quality. We propose a recording and rendering method based on Ambisonics that utilizes a perceptually-motivated approach to compensate for the reverberation of the playback room. The recorded direct and reverberant sound field components in the spherical harmonics (SHs) domain are spectrally and spatially compensated to preserve the relevant auditory cues including the direction of arrival of the direct sound, the spectral energy of the direct and reverberant sound components, and the Interaural Coherence (IC) across each auditory band. In contrast to the conventional Ambisonics, a flexible number of Ambisonics channels can be used for audio rendering. Listening test results show that the proposed method provides a perceptually accurate rendering of the originally recorded sound field, outperforming both conventional Ambisonics without compensation and even ideal Ambisonics rendering in a simulated anechoic room. Additionally, subjective evaluations of listeners seated at the center of the loudspeaker array demonstrate that the method remains robust to head rotation and minor displacements.</p></details> | <details><summary>The m...</summary><p>The manuscript was submitted to the JASA and is under review</p></details> |
| **[Spatially Filtered Sparse Bayesian Learning for Direction-of-Arrival Estimation with Leaky-Wave Antennas](https://arxiv.org/abs/2510.10796v1)** | 2025-10-12 | <details><summary>Show</summary><p>Direction-of-arrival (DoA) estimation with leaky-wave antennas (LWAs) offers a compact and cost-effective alternative to conventional antenna arrays but remains challenging in the presence of coherent sources. To address this issue, we propose a spatially filtered sparse Bayesian learning (SF-SBL) framework. Firstly, the field of view (FoV) is divided into angular sectors according to the frequency beam-scanning property of LWAs, and Bayesian inverse problems are then solved within each sector to improve efficiency and reduce computational cost. Both on-grid SBL and off-grid SBL formulations are developed. Simulation results show that the proposed approach achieves robust and accurate DoA estimation, even with coherent sources.</p></details> | <details><summary>Prepr...</summary><p>Preprint submitted to ICASSP 2026. 4 pages, 3 figures</p></details> |
| **[SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite Systems](https://arxiv.org/abs/2505.07714v2)** | 2025-10-09 | <details><summary>Show</summary><p>In this paper, we investigate downlink co-frequency interference (CFI) mitigation in non-geostationary satellites orbits (NGSOs) co-existing systems. Traditional mitigation techniques, such as Zero-forcing (ZF), produce a null towards the direction of arrivals (DOAs) of the interfering signals, but they suffer from high computational complexity due to matrix inversions and required knowledge of the channel state information (CSI). Furthermore, adaptive beamformers, such as sample matrix inversion (SMI)-based minimum variance, provide poor performance when the available snapshots are limited. We propose a Mamba-based beamformer (MambaBF) that leverages an unsupervised deep learning (DL) approach and can be deployed on the user terminal (UT) antenna array, for assisting downlink beamforming and CFI mitigation using only a limited number of available array snapshots as input, and without CSI knowledge. Simulation results demonstrate that MambaBF consistently outperforms conventional beamforming techniques in mitigating interference and maximizing the signal-to-interference-plus-noise ratio (SINR), particularly under challenging conditions characterized by low SINR, limited snapshots, and imperfect CSI.</p></details> |  |
| **[Multi-Source Position and Direction-of-Arrival Estimation Based on Euclidean Distance Matrices](https://arxiv.org/abs/2510.02556v1)** | 2025-10-02 | <details><summary>Show</summary><p>A popular method to estimate the positions or directions-of-arrival (DOAs) of multiple sound sources using an array of microphones is based on steered-response power (SRP) beamforming. For a three-dimensional scenario, SRP-based methods need to jointly optimize three continuous variables for position estimation or two continuous variables for DOA estimation, which can be computationally expensive. In this paper, we propose novel methods for multi-source position and DOA estimation by exploiting properties of Euclidean distance matrices (EDMs) and their respective Gram matrices. In the proposed multi-source position estimation method only a single continuous variable, representing the distance between each source and a reference microphone, needs to be optimized. For each source, the optimal continuous distance variable and set of candidate time-difference of arrival (TDOA) estimates are determined by minimizing a cost function that is defined using the eigenvalues of the Gram matrix. The estimated relative source positions are then mapped to estimated absolute source positions by solving an orthogonal Procrustes problem for each source. The proposed multi-source DOA estimation method entirely eliminates the need for continuous variable optimization by defining a relative coordinate system per source such that one of its coordinate axes is aligned with the respective source DOA. The optimal set of candidate TDOA estimates is determined by minimizing a cost function that is defined using the eigenvalues of a rank-reduced Gram matrix. The computational cost of the proposed EDM-based methods is significantly reduced compared to the SRP-based methods. Experimental results for different source and microphone configurations show that the proposed EDM-based method consistently outperforms the SRP-based method in terms of two-source position and DOA estimation accuracy.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 6 figures, submitted to IEEE Transactions on Audio, Speech and Language Processing (awaiting review)</p></details> |
| **[Joint DOA and Attitude Sensing Based on Tri-Polarized Continuous Aperture Array](https://arxiv.org/abs/2510.02029v1)** | 2025-10-02 | <details><summary>Show</summary><p>This paper investigates joint direction-of-arrival (DOA) and attitude sensing using tri-polarized continuous aperture arrays (CAPAs). By employing electromagnetic (EM) information theory, the spatially continuous received signals in tri-polarized CAPA are modeled, thereby enabling accurate DOA and attitude estimation. To facilitate subspace decomposition for continuous operators, an equivalent continuous-discrete transformation technique is developed. Moreover, both self- and cross-covariances of tri-polarized signals are exploited to construct a tri-polarized spectrum, significantly enhancing DOA estimation performance. Theoretical analyses reveal that the identifiability of attitude information fundamentally depends on the availability of prior target snapshots. Accordingly, two attitude estimation algorithms are proposed: one capable of estimating partial attitude information without prior knowledge, and the other achieving full attitude estimation when such knowledge is available. Numerical results demonstrate the feasibility and superiority of the proposed framework.</p></details> | 13 pages, 10 figures |
| **[Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming](https://arxiv.org/abs/2510.17823v1)** | 2025-09-30 | <details><summary>Show</summary><p>This work proposes an efficient, robust adaptive beamforming technique to deal with steering vector (SV) estimation mismatches and data covariance matrix reconstruction problems. In particular, the direction-of-arrival(DoA) of interfering sources is estimated with available snapshots in which the angular sectors of the interfering signals are computed adaptively. Then, we utilize the well-known general linear combination algorithm to reconstruct the interference-plus-noise covariance (IPNC) matrix using preprocessing-based spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be replaced by the sample covariance matrix (SCM) in the shrinkage method. A power spectrum sampling strategy is then devised based on a preprocessing matrix computed with the estimated angular sectors' information. Moreover, the covariance matrix for the signal is formed for the angular sector of the signal-of-interest (SOI), which allows for calculating an SV for the SOI using the power method. An analysis of the array beampattern in the proposed PPBSS technique is carried out, and a study of the computational cost of competing approaches is conducted. Simulation results show the proposed method's effectiveness compared to existing approaches.</p></details> | 13 figures, 14 pages |
| **[Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach](https://arxiv.org/abs/2510.17818v1)** | 2025-09-27 | <details><summary>Show</summary><p>This paper tackles the challenging problem of gridless two-dimensional (2D) direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a single snapshot of data. Conventional gridless methods often fail in this scenario due to prohibitive computational costs or a lack of robustness. We propose a novel framework that overcomes these limitations by jointly estimating a manifold transformation matrix and the source azimuth-elevation pairs within a single, unified optimization problem. This problem is solved efficiently using an inexact Augmented Lagrangian Method (iALM), which completely circumvents the need for semidefinite programming. By unifying the objectives of data fidelity and transformation robustness, our approach is uniquely suited for the demanding single-snapshot case. Simulation results confirm that the proposed iALM framework provides robust and high-resolution, gridless 2D-DOA estimates, establishing its efficacy for challenging array signal processing applications.</p></details> |  |
| **[Mixture-of-Experts Framework for Field-of-View Enhanced Signal-Dependent Binauralization of Moving Talkers](https://arxiv.org/abs/2509.13548v3)** | 2025-09-25 | <details><summary>Show</summary><p>We propose a novel mixture of experts framework for field-of-view enhancement in binaural signal matching. Our approach enables dynamic spatial audio rendering that adapts to continuous talker motion, allowing users to emphasize or suppress sounds from selected directions while preserving natural binaural cues. Unlike traditional methods that rely on explicit direction-of-arrival estimation or operate in the Ambisonics domain, our signal-dependent framework combines multiple binaural filters in an online manner using implicit localization. This allows for real-time tracking and enhancement of moving sound sources, supporting applications such as speech focus, noise reduction, and world-locked audio in augmented and virtual reality. The method is agnostic to array geometry offering a flexible solution for spatial audio capture and personalized playback in next-generation consumer audio devices.</p></details> | 5 pages, 3 figures |
| **[Single-Snapshot Localization Using Sparse Extremely Large Aperture Arrays](https://arxiv.org/abs/2509.17511v1)** | 2025-09-22 | <details><summary>Show</summary><p>This paper investigates single-snapshot direction-of-arrival (DOA) estimation and target localization with coherent sparse extremely large aperture arrays (ELAAs) in automotive radar applications. Far-field and near-field signal models are formulated for distributed bistatic configurations. To enable noncoherent processing, a single-snapshot MUSIC (SS-MUSIC) algorithm is proposed to fuse local spectra from individual subarrays and extended to near-field localization via geometric intersection. For coherent processing, a single-snapshot ESPRIT (SS-ESPRIT) method with ambiguity dealiasing is developed to fully exploit the aperture of sparse ELAAs for high-resolution angle estimation. Simulation results demonstrate that SS-ESPRIT provides superior angular resolution for closely spaced far-field targets, while SS-MUSIC offers robustness in near-field localization and flexibility in hybrid scenarios.</p></details> | <details><summary>ICASS...</summary><p>ICASSP 2026 manuscript under review</p></details> |
| **[(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation](https://arxiv.org/abs/2509.15475v1)** | 2025-09-18 | <details><summary>Show</summary><p>We consider the problem of estimating the directions of arrival (DOAs) of multiple sources from a single snapshot of an antenna array, a task with many practical applications. In such settings, the classical Bartlett beamformer is commonly used, as maximum likelihood estimation becomes impractical when the number of sources is unknown or large, and spectral methods based on the sample covariance are not applicable due to the lack of multiple snapshots. However, the accuracy and resolution of the Bartlett beamformer are fundamentally limited by the array aperture. In this paper, we propose a deep learning technique, comprising a novel architecture and training strategy, for generating a high-resolution spatial spectrum from a single snapshot. Specifically, we train a deep neural network that takes the measurements and a hypothesis angle as input and learns to output a score consistent with the capabilities of a much wider array. At inference time, a heatmap can be produced by scanning an arbitrary set of angles. We demonstrate the advantages of our trained model, named (SP)$^2$-Net, over the Bartlett beamformer and sparsity-based DOA estimation methods.</p></details> | <details><summary>Code ...</summary><p>Code can be found at https://github.com/Liozb/SP2-Net</p></details> |

## Speech Acoustic
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[A Study of Binaural Deep Beamforming With Interpretable Beampatterns Guided by Time-Varying RTF](https://arxiv.org/abs/2511.10168v1)** | 2025-11-13 | <details><summary>Show</summary><p>In this work, a deep beamforming framework for speech enhancement in dynamic acoustic environments is studied. The time-varying beamformer weights are estimated from the noisy multichannel signals by minimizing an SI-SDR loss. The estimation is guided by the continuously tracked relative transfer functions (RTFs) of the moving target speaker. The spatial behavior of the network is evaluated through both narrowband and wideband beampatterns under three settings: (i) oracle guidance using true RTFs, (ii) estimated RTFs obtained by a subspace tracking method, and (iii) without the RTF guidance. Results show that RTF-guided models produce smoother, spatially consistent beampatterns that accurately track the target's direction of arrival. In contrast, the model fails to maintain a clear spatial focus when guidance is absent. Using the estimated RTFs as guidance closely matches the oracle RTF behavior, confirming the effectiveness of the tracking scheme. The model also outputs a binaural signal to preserve the speaker's spatial cues, which promotes hearing aid and hearables applications.</p></details> | 5 pages, 6 figures |
| **[DOA Estimation with Lightweight Network on LLM-Aided Simulated Acoustic Scenes](https://arxiv.org/abs/2511.08012v1)** | 2025-11-11 | <details><summary>Show</summary><p>Direction-of-Arrival (DOA) estimation is critical in spatial audio and acoustic signal processing, with wide-ranging applications in real-world. Most existing DOA models are trained on synthetic data by convolving clean speech with room impulse responses (RIRs), which limits their generalizability due to constrained acoustic diversity. In this paper, we revisit DOA estimation using a recently introduced dataset constructed with the assistance of large language models (LLMs), which provides more realistic and diverse spatial audio scenes. We benchmark several representative neural-based DOA methods on this dataset and propose LightDOA, a lightweight DOA estimation model based on depthwise separable convolutions, specifically designed for mutil-channel input in varying environments. Experimental results show that LightDOA achieves satisfactory accuracy and robustness across various acoustic scenes while maintaining low computational complexity. This study not only highlights the potential of spatial audio synthesized with the assistance of LLMs in advancing robust and efficient DOA estimation research, but also highlights LightDOA as efficient solution for resource-constrained applications.</p></details> |  |
| **[Sound Source Localization for Human-Robot Interaction in Outdoor Environments](https://arxiv.org/abs/2507.21431v1)** | 2025-07-29 | <details><summary>Show</summary><p>This paper presents a sound source localization strategy that relies on a microphone array embedded in an unmanned ground vehicle and an asynchronous close-talking microphone near the operator. A signal coarse alignment strategy is combined with a time-domain acoustic echo cancellation algorithm to estimate a time-frequency ideal ratio mask to isolate the target speech from interferences and environmental noise. This allows selective sound source localization, and provides the robot with the direction of arrival of sound from the active operator, which enables rich interaction in noisy scenarios. Results demonstrate an average angle error of 4 degrees and an accuracy within 5 degrees of 95\% at a signal-to-noise ratio of 1dB, which is significantly superior to the state-of-the-art localization methods.</p></details> |  |
| **[Multi-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival Estimation](https://arxiv.org/abs/2505.19493v2)** | 2025-06-06 | <details><summary>Show</summary><p>Acoustic echo cancellation (AEC) is an important speech signal processing technology that can remove echoes from microphone signals to enable natural-sounding full-duplex speech communication. While single-channel AEC is widely adopted, multi-channel AEC can leverage spatial cues afforded by multiple microphones to achieve better performance. Existing multi-channel AEC approaches typically combine beamforming with deep neural networks (DNN). This work proposes a two-stage algorithm that enhances multi-channel AEC by incorporating sound source directional cues. Specifically, a lightweight DNN is first trained to predict the sound source directions, and then the predicted directional information, multi-channel microphone signals, and single-channel far-end signal are jointly fed into an AEC network to estimate the near-end signal. Evaluation results show that the proposed algorithm outperforms baseline approaches and exhibits robust generalization across diverse acoustic environments.</p></details> | <details><summary>Accep...</summary><p>Accepted by Interspeech 2025</p></details> |
| **[HRTF Estimation using a Score-based Prior](https://arxiv.org/abs/2410.01562v1)** | 2024-10-02 | <details><summary>Show</summary><p>We present a head-related transfer function (HRTF) estimation method which relies on a data-driven prior given by a score-based diffusion model. The HRTF is estimated in reverberant environments using natural excitation signals, e.g. human speech. The impulse response of the room is estimated along with the HRTF by optimizing a parametric model of reverberation based on the statistical behaviour of room acoustics. The posterior distribution of HRTF given the reverberant measurement and excitation signal is modelled using the score-based HRTF prior and a log-likelihood approximation. We show that the resulting method outperforms several baselines, including an oracle recommender system that assigns the optimal HRTF in our training set based on the smallest distance to the true HRTF at the given direction of arrival. In particular, we show that the diffusion prior can account for the large variability of high-frequency content in HRTFs.</p></details> |  |
| **[A Real-Time Active Speaker Detection System Integrating an Audio-Visual Signal with a Spatial Querying Mechanism](https://arxiv.org/abs/2309.08295v1)** | 2023-09-15 | <details><summary>Show</summary><p>We introduce a distinctive real-time, causal, neural network-based active speaker detection system optimized for low-power edge computing. This system drives a virtual cinematography module and is deployed on a commercial device. The system uses data originating from a microphone array and a 360-degree camera. Our network requires only 127 MFLOPs per participant, for a meeting with 14 participants. Unlike previous work, we examine the error rate of our network when the computational budget is exhausted, and find that it exhibits graceful degradation, allowing the system to operate reasonably well even in this case. Departing from conventional DOA estimation approaches, our network learns to query the available acoustic data, considering the detected head locations. We train and evaluate our algorithm on a realistic meetings dataset featuring up to 14 participants in the same meeting, overlapped speech, and other challenging scenarios.</p></details> |  |
| **[Localizing Spatial Information in Neural Spatiospectral Filters](https://arxiv.org/abs/2303.08052v2)** | 2023-07-03 | <details><summary>Show</summary><p>Beamforming for multichannel speech enhancement relies on the estimation of spatial characteristics of the acoustic scene. In its simplest form, the delay-and-sum beamformer (DSB) introduces a time delay to all channels to align the desired signal components for constructive superposition. Recent investigations of neural spatiospectral filtering revealed that these filters can be characterized by a beampattern similar to one of traditional beamformers, which shows that artificial neural networks can learn and explicitly represent spatial structure. Using the Complex-valued Spatial Autoencoder (COSPA) as an exemplary neural spatiospectral filter for multichannel speech enhancement, we investigate where and how such networks represent spatial information. We show via clustering that for COSPA the spatial information is represented by the features generated by a gated recurrent unit (GRU) layer that has access to all channels simultaneously and that these features are not source -- but only direction of arrival-dependent.</p></details> | <details><summary>Accep...</summary><p>Accepted to the 31st European Signal Processing Conference (EUSIPCO 2023), Helsinki, Finland. 5 pages, 3 figures</p></details> |
| **[Multi-microphone Automatic Speech Segmentation in Meetings Based on Circular Harmonics Features](https://arxiv.org/abs/2306.04268v1)** | 2023-06-07 | <details><summary>Show</summary><p>Speaker diarization is the task of answering Who spoke and when? in an audio stream. Pipeline systems rely on speech segmentation to extract speakers' segments and achieve robust speaker diarization. This paper proposes a common framework to solve three segmentation tasks in the distant speech scenario: Voice Activity Detection (VAD), Overlapped Speech Detection (OSD), and Speaker Change Detection (SCD). In the literature, a few studies investigate the multi-microphone distant speech scenario. In this work, we propose a new set of spatial features based on direction-of-arrival estimations in the circular harmonic domain (CH-DOA). These spatial features are extracted from multi-microphone audio data and combined with standard acoustic features. Experiments on the AMI meeting corpus show that CH-DOA can improve the segmentation while being robust in the case of deactivated microphones.</p></details> | <details><summary>Inter...</summary><p>Interspeech 2023, international Speech Communication Association (ISCA), Aug 2023, Dublin, Ireland</p></details> |
| **[ConceptBeam: Concept Driven Target Speech Extraction](https://arxiv.org/abs/2207.11964v1)** | 2022-07-25 | <details><summary>Show</summary><p>We propose a novel framework for target speech extraction based on semantic information, called ConceptBeam. Target speech extraction means extracting the speech of a target speaker in a mixture. Typical approaches have been exploiting properties of audio signals, such as harmonic structure and direction of arrival. In contrast, ConceptBeam tackles the problem with semantic clues. Specifically, we extract the speech of speakers speaking about a concept, i.e., a topic of interest, using a concept specifier such as an image or speech. Solving this novel problem would open the door to innovative applications such as listening systems that focus on a particular topic discussed in a conversation. Unlike keywords, concepts are abstract notions, making it challenging to directly represent a target concept. In our scheme, a concept is encoded as a semantic embedding by mapping the concept specifier to a shared embedding space. This modality-independent space can be built by means of deep metric learning using paired data consisting of images and their spoken captions. We use it to bridge modality-dependent information, i.e., the speech segments in the mixture, and the specified, modality-independent concept. As a proof of our scheme, we performed experiments using a set of images associated with spoken captions. That is, we generated speech mixtures from these spoken captions and used the images or speech signals as the concept specifiers. We then extracted the target speech using the acoustic characteristics of the identified segments. We compare ConceptBeam with two methods: one based on keywords obtained from recognition systems and another based on sound source separation. We show that ConceptBeam clearly outperforms the baseline methods and effectively extracts speech based on the semantic representation.</p></details> | <details><summary>Accep...</summary><p>Accepted to ACM Multimedia 2022</p></details> |
| **[Comparison of Binaural RTF-Vector-Based Direction of Arrival Estimation Methods Exploiting an External Microphone](https://arxiv.org/abs/2104.05079v2)** | 2022-05-18 | <details><summary>Show</summary><p>In this paper we consider a binaural hearing aid setup, where in addition to the head-mounted microphones an external microphone is available. For this setup, we investigate the performance of several relative transfer function (RTF) vector estimation methods to estimate the direction of arrival (DOA) of the target speaker in a noisy and reverberant acoustic environment. More in particular, we consider the state-of-the-art covariance whitening (CW) and covariance subtraction (CS) methods, either incorporating the external microphone or not, and the recently proposed spatial coherence (SC) method, requiring the external microphone. To estimate the DOA from the estimated RTF vector, we propose to minimize the frequency-averaged Hermitian angle between the estimated head-mounted RTF vector and a database of prototype head-mounted RTF vectors. Experimental results with stationary and moving speech sources in a reverberant environment with diffuse-like noise show that the SC method outperforms the CS method and yields a similar DOA estimation accuracy as the CW method at a lower computational complexity.</p></details> | <details><summary>\c{op...</summary><p>\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[Learning Deep Direct-Path Relative Transfer Function for Binaural Sound Source Localization](https://arxiv.org/abs/2202.07841v1)** | 2022-02-16 | <details><summary>Show</summary><p>Direct-path relative transfer function (DP-RTF) refers to the ratio between the direct-path acoustic transfer functions of two microphone channels. Though DP-RTF fully encodes the sound spatial cues and serves as a reliable localization feature, it is often erroneously estimated in the presence of noise and reverberation. This paper proposes to learn DP-RTF with deep neural networks for robust binaural sound source localization. A DP-RTF learning network is designed to regress the binaural sensor signals to a real-valued representation of DP-RTF. It consists of a branched convolutional neural network module to separately extract the inter-channel magnitude and phase patterns, and a convolutional recurrent neural network module for joint feature learning. To better explore the speech spectra to aid the DP-RTF estimation, a monaural speech enhancement network is used to recover the direct-path spectrograms from the noisy ones. The enhanced spectrograms are stacked onto the noisy spectrograms to act as the input of the DP-RTF learning network. We train one unique DP-RTF learning network using many different binaural arrays to enable the generalization of DP-RTF learning across arrays. This way avoids time-consuming training data collection and network retraining for a new array, which is very useful in practical application. Experimental results on both simulated and real-world data show the effectiveness of the proposed method for direction of arrival (DOA) estimation in the noisy and reverberant environment, and a good generalization ability to unseen binaural arrays.</p></details> | <details><summary>Accep...</summary><p>Accepted by TASLP 2021</p></details> |
| **[Signal-Aware Direction-of-Arrival Estimation Using Attention Mechanisms](https://arxiv.org/abs/2201.00503v1)** | 2022-01-03 | <details><summary>Show</summary><p>The direction-of-arrival (DOA) of sound sources is an essential acoustic parameter used, e.g., for multi-channel speech enhancement or source tracking. Complex acoustic scenarios consisting of sources-of-interest, interfering sources, reverberation, and noise make the estimation of the DOAs corresponding to the sources-of-interest a challenging task. Recently proposed attention mechanisms allow DOA estimators to focus on the sources-of-interest and disregard interference and noise, i.e., they are signal-aware. The attention is typically obtained by a deep neural network (DNN) from a short-time Fourier transform (STFT) based representation of a single microphone signal. Subsequently, attention has been applied as binary or ratio weighting to STFT-based microphone signal representations to reduce the impact of frequency bins dominated by noise, interference, or reverberation. The impact of attention on DOA estimators and different training strategies for attention and DOA DNNs are not yet studied in depth. In this paper, we evaluate systems consisting of different DNNs and signal processing-based methods for DOA estimation when attention is applied. Additionally, we propose training strategies for attention-based DOA estimation optimized via a DOA objective, i.e., end-to-end. The evaluation of the proposed and the baseline systems is performed using data generated with simulated and measured room impulse responses under various acoustic conditions, like reverberation times, noise, and source array distances. Overall, DOA estimation using attention in combination with signal-processing methods exhibits a far lower computational complexity than a fully DNN-based system; however, it yields comparable results.</p></details> |  |
| **[Directional MCLP Analysis and Reconstruction for Spatial Speech Communication](https://arxiv.org/abs/2109.04544v1)** | 2021-09-09 | <details><summary>Show</summary><p>Spatial speech communication, i.e., the reconstruction of spoken signal along with the relative speaker position in the enclosure (reverberation information) is considered in this paper. Directional, diffuse components and the source position information are estimated at the transmitter, and perceptually effective reproduction is considered at the receiver. We consider spatially distributed microphone arrays for signal acquisition, and node specific signal estimation, along with its direction of arrival (DoA) estimation. Short-time Fourier transform (STFT) domain multi-channel linear prediction (MCLP) approach is used to model the diffuse component and relative acoustic transfer function is used to model the direct signal component. Distortion-less array response constraint and the time-varying complex Gaussian source model are used in the joint estimation of source DoA and the constituent signal components, separately at each node. The intersection between DoA directions at each node is used to compute the source position. Signal components computed at the node nearest to the estimated source position are taken as the signals for transmission. At the receiver, a four channel loud speaker (LS) setup is used for spatial reproduction, in which the source spatial image is reproduced relative to a chosen virtual listener position in the transmitter enclosure. Vector base amplitude panning (VBAP) method is used for direct component reproduction using the LS setup and the diffuse component is reproduced equally from all the loud speakers after decorrelation. This scheme of spatial speech communication is shown to be effective and more natural for hands-free telecommunication, through either loudspeaker listening or binaural headphone listening with head related transfer function (HRTF) based presentation.</p></details> | <details><summary>The m...</summary><p>The manuscript is submitted as a full paper to IEEE/ACM Transactions on Audio, Speech and Language Processing</p></details> |
| **[Direction of Arrival Estimation of Noisy Speech Using Convolutional Recurrent Neural Networks with Higher-Order Ambisonics Signals](https://arxiv.org/abs/2102.09853v3)** | 2021-05-06 | <details><summary>Show</summary><p>Training convolutional recurrent neural networks on first-order Ambisonics signals is a well-known approach when estimating the direction of arrival for speech/sound signals. In this work, we investigate whether increasing the order of Ambisonics up to the fourth order further improves the estimation performance of convolutional recurrent neural networks. While our results on data based on simulated spatial room impulse responses show that the use of higher Ambisonics orders does have the potential to provide better localization results, no further improvement was shown on data based on real spatial room impulse responses from order two onwards. Rather, it seems to be crucial to extract meaningful features from the raw data. First order features derived from the acoustic intensity vector were superior to pure higher-order magnitude and phase features in almost all scenarios.</p></details> | <details><summary>5 pag...</summary><p>5 pages, 6 figures. Accepted to EUSIPCO 2021</p></details> |
| **[Semi-supervised source localization in reverberant environments with deep generative modeling](https://arxiv.org/abs/2101.10636v2)** | 2021-04-01 | <details><summary>Show</summary><p>We propose a semi-supervised approach to acoustic source localization in reverberant environments based on deep generative modeling. Localization in reverberant environments remains an open challenge. Even with large data volumes, the number of labels available for supervised learning in reverberant environments is usually small. We address this issue by performing semi-supervised learning (SSL) with convolutional variational autoencoders (VAEs) on reverberant speech signals recorded with microphone arrays. The VAE is trained to generate the phase of relative transfer functions (RTFs) between microphones, in parallel with a direction of arrival (DOA) classifier based on RTF-phase. These models are trained using both labeled and unlabeled RTF-phase sequences. In learning to perform these tasks, the VAE-SSL explicitly learns to separate the physical causes of the RTF-phase (i.e., source location) from distracting signal characteristics such as noise and speech activity. Relative to existing semi-supervised localization methods in acoustics, VAE-SSL is effectively an end-to-end processing approach which relies on minimal preprocessing of RTF-phase features. As far as we are aware, our paper presents the first approach to modeling the physics of acoustic propagation using deep generative modeling. The VAE-SSL approach is compared with two signal processing-based approaches, steered response power with phase transform (SRP-PHAT) and MUltiple SIgnal Classification (MUSIC), as well as fully supervised CNNs. We find that VAE-SSL can outperform the conventional approaches and the CNN in label-limited scenarios. Further, the trained VAE-SSL system can generate new RTF-phase samples, which shows the VAE-SSL approach learns the physics of the acoustic environment. The generative modeling in VAE-SSL thus provides a means of interpreting the learned representations.</p></details> | <details><summary>Revis...</summary><p>Revision, submitted to IEEE Access</p></details> |
| **[DBNET: DOA-driven beamforming network for end-to-end farfield sound source separation](https://arxiv.org/abs/2010.11566v1)** | 2020-10-22 | <details><summary>Show</summary><p>Many deep learning techniques are available to perform source separation and reduce background noise. However, designing an end-to-end multi-channel source separation method using deep learning and conventional acoustic signal processing techniques still remains challenging. In this paper we propose a direction-of-arrival-driven beamforming network (DBnet) consisting of direction-of-arrival (DOA) estimation and beamforming layers for end-to-end source separation. We propose to train DBnet using loss functions that are solely based on the distances between the separated speech signals and the target speech signals, without a need for the ground-truth DOAs of speakers. To improve the source separation performance, we also propose end-to-end extensions of DBnet which incorporate post masking networks. We evaluate the proposed DBnet and its extensions on a very challenging dataset, targeting realistic far-field sound source separation in reverberant and noisy environments. The experimental results show that the proposed extended DBnet using a convolutional-recurrent post masking network outperforms state-of-the-art source separation methods.</p></details> | 5 pages, 4 figures |
| **[GEV Beamforming Supported by DOA-based Masks Generated on Pairs of Microphones](https://arxiv.org/abs/2005.09587v2)** | 2020-08-05 | <details><summary>Show</summary><p>Distant speech processing is a challenging task, especially when dealing with the cocktail party effect. Sound source separation is thus often required as a preprocessing step prior to speech recognition to improve the signal to distortion ratio (SDR). Recently, a combination of beamforming and speech separation networks have been proposed to improve the target source quality in the direction of arrival of interest. However, with this type of approach, the neural network needs to be trained in advance for a specific microphone array geometry, which limits versatility when adding/removing microphones, or changing the shape of the array. The solution presented in this paper is to train a neural network on pairs of microphones with different spacing and acoustic environmental conditions, and then use this network to estimate a time-frequency mask from all the pairs of microphones forming the array with an arbitrary shape. Using this mask, the target and noise covariance matrices can be estimated, and then used to perform generalized eigenvalue (GEV) beamforming. Results show that the proposed approach improves the SDR from 4.78 dB to 7.69 dB on average, for various microphone array geometries that correspond to commercially available hardware.</p></details> |  |
| **[Broadband DOA estimation using Convolutional neural networks trained with noise signals](https://arxiv.org/abs/1705.00919v2)** | 2017-12-12 | <details><summary>Show</summary><p>A convolution neural network (CNN) based classification method for broadband DOA estimation is proposed, where the phase component of the short-time Fourier transform coefficients of the received microphone signals are directly fed into the CNN and the features required for DOA estimation are learnt during training. Since only the phase component of the input is used, the CNN can be trained with synthesized noise signals, thereby making the preparation of the training data set easier compared to using speech signals. Through experimental evaluation, the ability of the proposed noise trained CNN framework to generalize to speech sources is demonstrated. In addition, the robustness of the system to noise, small perturbations in microphone positions, as well as its ability to adapt to different acoustic conditions is investigated using experiments with simulated and real data.</p></details> | <details><summary>Publi...</summary><p>Published in Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2017</p></details> |
| **[Spatial Diffuseness Features for DNN-Based Speech Recognition in Noisy and Reverberant Environments](https://arxiv.org/abs/1410.2479v2)** | 2015-02-16 | <details><summary>Show</summary><p>We propose a spatial diffuseness feature for deep neural network (DNN)-based automatic speech recognition to improve recognition accuracy in reverberant and noisy environments. The feature is computed in real-time from multiple microphone signals without requiring knowledge or estimation of the direction of arrival, and represents the relative amount of diffuse noise in each time and frequency bin. It is shown that using the diffuseness feature as an additional input to a DNN-based acoustic model leads to a reduced word error rate for the REVERB challenge corpus, both compared to logmelspec features extracted from noisy signals, and features enhanced by spectral subtraction.</p></details> | <details><summary>accep...</summary><p>accepted for ICASSP2015</p></details> |

## Broadband
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[A Unified Framework for Direction and Diffuseness Estimation Using Tight-Frame Microphone Arrays](https://arxiv.org/abs/2510.22183v2)** | 2025-10-28 | <details><summary>Show</summary><p>This work presents a unified framework for estimating both sound-field direction and diffuseness using practical microphone arrays with different spatial configurations. Building on covariance-based diffuseness models, we formulate a velocity-only covariance approach that enables consistent diffuseness evaluation across heterogeneous array geometries without requiring mode whitening or spherical-harmonic decomposition. Three array types -- an A-format array, a rigid-sphere array, and a newly proposed tight-frame array -- are modeled and compared through both simulations and measurement-based experiments. The results show that the tight-frame configuration achieves near-isotropic directional sampling and reproduces diffuseness characteristics comparable to those of higher-order spherical arrays, while maintaining a compact physical structure. We further examine the accuracy of direction-of-arrival estimation based on acoustic intensity within the same framework. These findings connect theoretical diffuseness analysis with implementable array designs and support the development of robust, broadband methods for spatial-sound-field characterization.</p></details> | <details><summary>36 pa...</summary><p>36 pages including 14 files</p></details> |
| **[Ambiguity-Free Broadband DOA Estimation Relying on Parameterized Time-Frequency Transform](https://arxiv.org/abs/2503.03691v1)** | 2025-03-05 | <details><summary>Show</summary><p>An ambiguity-free direction-of-arrival (DOA) estimation scheme is proposed for sparse uniform linear arrays under low signal-to-noise ratios (SNRs) and non-stationary broadband signals. First, for achieving better DOA estimation performance at low SNRs while using non-stationary signals compared to the conventional frequency-difference (FD) paradigms, we propose parameterized time-frequency transform-based FD processing. Then, the unambiguous compressive FD beamforming is conceived to compensate the resolution loss induced by difference operation. Finally, we further derive a coarse-to-fine histogram statistics scheme to alleviate the perturbation in compressive FD beamforming with good DOA estimation accuracy. Simulation results demonstrate the superior performance of our proposed algorithm regarding robustness, resolution, and DOA estimation accuracy.</p></details> | 6 figures |
| **[Fully Bayesian Wideband Direction-of-Arrival Estimation and Detection via RJMCMC](https://arxiv.org/abs/2412.08895v1)** | 2024-12-12 | <details><summary>Show</summary><p>We propose a fully Bayesian approach to wideband, or broadband, direction-of-arrival (DoA) estimation and signal detection. Unlike previous works in wideband DoA estimation and detection, where the signals were modeled in the time-frequency domain, we directly model the time-domain representation and treat the non-causal part of the source signal as latent variables. Furthermore, our Bayesian model allows for closed-form marginalization of the latent source signals by leveraging conjugacy. To further speed up computation, we exploit the sparse ``stripe matrix structure'' of the considered system, which stems from the circulant matrix representation of linear time-invariant (LTI) systems. This drastically reduces the time complexity of computing the likelihood from $\mathcal{O}(N^3 k^3)$ to $\mathcal{O}(N k^3)$, where $N$ is the number of samples received by the array and $k$ is the number of sources. These computational improvements allow for efficient posterior inference through reversible jump Markov chain Monte Carlo (RJMCMC). We use the non-reversible extension of RJMCMC (NRJMCMC), which often achieves lower autocorrelation and faster convergence than the conventional reversible variant. Detection, estimation, and reconstruction of the latent source signals can then all be performed in a fully Bayesian manner through the samples drawn using NRJMCMC. We evaluate the detection performance of the procedure by comparing against generalized likelihood ratio testing (GLRT) and information criteria.</p></details> |  |
| **[Comparison of Frequency-Fusion Mechanisms for Binaural Direction-of-Arrival Estimation for Multiple Speakers](https://arxiv.org/abs/2401.07849v1)** | 2024-01-15 | <details><summary>Show</summary><p>To estimate the direction of arrival (DOA) of multiple speakers with methods that use prototype transfer functions, frequency-dependent spatial spectra (SPS) are usually constructed. To make the DOA estimation robust, SPS from different frequencies can be combined. According to how the SPS are combined, frequency fusion mechanisms are categorized into narrowband, broadband, or speaker-grouped, where the latter mechanism requires a speaker-wise grouping of frequencies. For a binaural hearing aid setup, in this paper we propose an interaural time difference (ITD)-based speaker-grouped frequency fusion mechanism. By exploiting the DOA dependence of ITDs, frequencies can be grouped according to a common ITD and be used for DOA estimation of the respective speaker. We apply the proposed ITD-based speaker-grouped frequency fusion mechanism for different DOA estimation methods, namely the multiple signal classification, steered response power and a recently published method based on relative transfer function (RTF) vectors. In our experiments, we compare DOA estimation with different fusion mechanisms. For all considered DOA estimation methods, the proposed ITD-based speaker-grouped frequency fusion mechanism results in a higher DOA estimation accuracy compared with the narrowband and broadband fusion mechanisms.</p></details> | <details><summary>Accep...</summary><p>Accepted for ICASSP 2024</p></details> |
| **[Gridless DOA Estimation with Multiple Frequencies](https://arxiv.org/abs/2207.06159v2)** | 2023-02-06 | <details><summary>Show</summary><p>Direction-of-arrival (DOA) estimation is widely applied in acoustic source localization. A multi-frequency model is suitable for characterizing the broadband structure in acoustic signals. In this paper, the continuous (gridless) DOA estimation problem with multiple frequencies is considered. This problem is formulated as an atomic norm minimization (ANM) problem. The ANM problem is equivalent to a semi-definite program (SDP) which can be solved by an off-the-shelf SDP solver. The dual certificate condition is provided to certify the optimality of the SDP solution so that the sources can be localized by finding the roots of a polynomial. We also construct the dual polynomial to satisfy the dual certificate condition and show that such a construction exists when the source amplitude has a uniform magnitude. In multi-frequency ANM, spatial aliasing of DOAs at higher frequencies can cause challenges. We discuss this issue extensively and propose a robust solution to combat aliasing. Numerical results support our theoretical findings and demonstrate the effectiveness of the proposed method.</p></details> | <details><summary>This ...</summary><p>This work has been accepted by IEEE Transactions on Signal Processing</p></details> |
| **[DA-MUSIC: Data-Driven DoA Estimation via Deep Augmented MUSIC Algorithm](https://arxiv.org/abs/2109.10581v5)** | 2023-01-11 | <details><summary>Show</summary><p>Direction of arrival (DoA) estimation of multiple signals is pivotal in sensor array signal processing. A popular multi-signal DoA estimation method is the multiple signal classification (MUSIC) algorithm, which enables high-performance super-resolution DoA recovery while being highly applicable in practice. MUSIC is a model-based algorithm, relying on an accurate mathematical description of the relationship between the signals and the measurements and assumptions on the signals themselves (non-coherent, narrowband sources). As such, it is sensitive to model imperfections. In this work we propose to overcome these limitations of MUSIC by augmenting the algorithm with specifically designed neural architectures. Our proposed deep augmented MUSIC (DA-MUSIC) algorithm is thus a hybrid model-based/data-driven DoA estimator, which leverages data to improve performance and robustness while preserving the interpretable flow of the classic method. DA-MUSIC is shown to learn to overcome limitations of the purely model-based method, such as its inability to successfully localize coherent sources as well as estimate the number of coherent signal sources present. We further demonstrate the superior resolution of the DA-MUSIC algorithm in synthetic narrowband and broadband scenarios as well as with real-world data of DoA estimation from seismic signals.</p></details> | Submitted to TVT |
| **[Wideband Modal Orthogonality: A New Approach for Broadband DOA Estimation](https://arxiv.org/abs/2006.07261v1)** | 2020-06-12 | <details><summary>Show</summary><p>Wideband direction of arrival (DOA) estimation techniques for sensors array have been studied extensively in the literature. Nevertheless, needing prior information on the number and directions of sources or demanding heavy computational load makes most of these techniques less useful in practice. In this paper, a low complexity subspace-based framework for DOA estimation of broadband signals, named as wideband modal orthogonality (WIMO), is proposed and accordingly two DOA estimators are developed. First, a closed-form approximation of spatial-temporal covariance matrix (STCM) in the uniform spectrum case is presented. The eigenvectors of STCM associated with non-zero eigenvalues are modal components of the wideband source in a given bandwidth and direction. WIMO idea is to extract these eigenvectors at desired DOAs from the approximated STCM and test their orthogonality to estimated noise subspace. In the non-uniform spectrum case, WIMO idea can be applied by approximating STCM through numerical integration. Fortunately, STCM approximation and modal extraction can be performed offline. WIMO provides DOA estimation without the conventional prerequisites, such as spectral decomposition, focusing procedure and, a priori information on the number of sources and their DOAs. Several numerical examples are conducted to compare the WIMO performance with the state-of-the-art methods. Simulations demonstrate that the two proposed DOA estimators achieve superior performance in terms of probability of resolution and estimation error along with orders of magnitude runtime speedup.</p></details> |  |
| **[Broadband Sparse Array Focusing Via Spatial Periodogram Averaging and Correlation Resampling](https://arxiv.org/abs/1912.11526v1)** | 2019-12-24 | <details><summary>Show</summary><p>This paper proposes two coherent broadband focusing algorithms for spatial correlation estimation using sparse linear arrays. Both algorithms decompose the time-domain array data into disjoint frequency bands through discrete Fourier transform or filter banks to obtain broadband frequency-domain snapshots. The periodogram averaging (AP) algorithm starts in the frequency domain by estimating the broadband spatial periodograms for all bands and then averaging them to reinforce the sources' spatial spectral information. Taking inverse spatial Fourier transform of the combined spatial periodogram estimates the focused spatial correlations. Alternatively, the spatial correlation resampling (SCR) algorithm directly computes the spatial correlations for each band and then rescales the spatial sampling rate to align at a focused frequency. The resampled spatial correlations from all frequency bands are then averaged to estimate the focused spatial correlations. The spatial correlations estimated from the AP or SCR algorithms populate the diagonals of a Hermitian Toeplitz augmented covariance matrix (ACM). The focused ACM is the input of a new minimum description length (MDL) based criteria, termed MDL-gap, for source enumeration and the standard narrowband MUSIC algorithm for DOA estimation. Numerical simulations show that both the AP and SCR algorithms improve source enumeration and DOA estimation performances over the incoherent subspace focusing algorithm in snapshot limited scenarios.</p></details> | 11 pages, 8 figures |
| **[Broadband DOA estimation using Convolutional neural networks trained with noise signals](https://arxiv.org/abs/1705.00919v2)** | 2017-12-12 | <details><summary>Show</summary><p>A convolution neural network (CNN) based classification method for broadband DOA estimation is proposed, where the phase component of the short-time Fourier transform coefficients of the received microphone signals are directly fed into the CNN and the features required for DOA estimation are learnt during training. Since only the phase component of the input is used, the CNN can be trained with synthesized noise signals, thereby making the preparation of the training data set easier compared to using speech signals. Through experimental evaluation, the ability of the proposed noise trained CNN framework to generalize to speech sources is demonstrated. In addition, the robustness of the system to noise, small perturbations in microphone positions, as well as its ability to adapt to different acoustic conditions is investigated using experiments with simulated and real data.</p></details> | <details><summary>Publi...</summary><p>Published in Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2017</p></details> |
| **[Convolutional Neural Networks for Passive Monitoring of a Shallow Water Environment using a Single Sensor](https://arxiv.org/abs/1612.03505v1)** | 2016-12-12 | <details><summary>Show</summary><p>A cost effective approach to remote monitoring of protected areas such as marine reserves and restricted naval waters is to use passive sonar to detect, classify, localize, and track marine vessel activity (including small boats and autonomous underwater vehicles). Cepstral analysis of underwater acoustic data enables the time delay between the direct path arrival and the first multipath arrival to be measured, which in turn enables estimation of the instantaneous range of the source (a small boat). However, this conventional method is limited to ranges where the Lloyd's mirror effect (interference pattern formed between the direct and first multipath arrivals) is discernible. This paper proposes the use of convolutional neural networks (CNNs) for the joint detection and ranging of broadband acoustic noise sources such as marine vessels in conjunction with a data augmentation approach for improving network performance in varied signal-to-noise ratio (SNR) situations. Performance is compared with a conventional passive sonar ranging method for monitoring marine vessel activity using real data from a single hydrophone mounted above the sea floor. It is shown that CNNs operating on cepstrum data are able to detect the presence and estimate the range of transiting vessels at greater distances than the conventional method.</p></details> | <details><summary>Final...</summary><p>Final draft for IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2017. 5 pages, 4 figures</p></details> |

